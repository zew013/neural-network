--- !Config
# This specifies the number of layers and number of hidden neurons in each layer.
# Note that the first and the last elements of the list indicate the input and
# output sizes
layer_specs: [3072, 128, 64, 10]  #Represents a 2 layer NN. 3072 is the input layer

# Type of non-linear activation function to be used for the layers.
activation: "ReLU"

# The learning rate to be used for training.
learning_rate: 0.01

# Number of training samples per batch to be passed to network
batch_size: 1024

# Number of epochs to train the model
epochs: 150

# Flag to enable early stopping
early_stop: True

# History for early stopping. Wait for this many epochs to check validation loss / accuracy.
early_stop_epoch: 50


# Regularization
regularization_type: "L1"
regularization_lambda: 0.0001


# Use momentum for training
momentum: True

# Value for the parameter 'gamma' in momentum
momentum_gamma: 0.9

#Weight Type
weight_type: "random"